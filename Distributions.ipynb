{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vectrlab/apex-stats-modules/blob/main/Distributions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w5Ax199wzyai"
      },
      "source": [
        "# APEX STATS Describing Distributions\n",
        "Module by David Schuster, based on APEX STATS code Andy Qui Le\n",
        "\n",
        "Licensed under CC BY-NC-SA\n",
        "\n",
        "This module shows one approach to using **APEX STATS code snippets + data examples**. You will be able to use and adapt this module, and you will be able to build your own modules using the **module construction kit**.\n",
        "\n",
        "<img src=\"https://c.pxhere.com/images/c7/fe/7d715cdd48d626a66e9a0cbe616a-1585043.jpg!d\" style=\"width:20em;\">\n",
        "\n",
        "Photo by <strong><a href=\"https://pxhere.com/en/photographer/767067?utm_content=clipUser&utm_medium=referral&utm_source=pxhere\">mohamed_hassan</a></strong> from <strong><a href=\"https://pxhere.com/en/photo/1585043?utm_content=clipUser&utm_medium=referral&utm_source=pxhere\">PxHere</a></strong></p>\n",
        "\n",
        "## I. Intro and Learning Objectives\n",
        "In this module, we will introduce some of the most fundamental and useful tools for making sense out of distributions of data. We call these **descriptive statistics**, and they are methods of summarizing a distribution of numbers in a single value. Imagine summarizing your performance in college in a single number, your GPA. While your GPA is informative, it is not the whole picture of your college performance. In the same way, we will see that single number summaries give us an informative, but incomplete, summary of data. However, when we examine several descriptive statistics, we are able to gain a much clearer summary of our data.\n",
        "\n",
        "We focus on quantitative distributions in the module, which have three properties that can be summarized. Distributions have **central tendency**, which is the value of the scores. Distributions have **spread** or **variability**, which is how different scores are from other scores in the distribution. Finally, distributions have a **shape** which becomes apaprent when they are graphed using a histogram. \n",
        "\n",
        "\n",
        "These exercises map onto several learning objective(s) for the C-ID descriptor for [Introduction to Statistics](https://c-id.net/descriptors/final/show/365). Upon successful completion of the course, you will be able to:  \n",
        "\n",
        "(1) Interpret data displayed in tables and graphically  \n",
        "\n",
        "(6, partial) Calculate probabilities using normal distributions\n",
        "\n",
        "(7, partial) Distinguish the difference between sample and population distributions\n",
        "\n",
        "---\n",
        "\n",
        "## II. Background Reading\n",
        "\n",
        "Read through the descriptive statistics chapter before class. When we meet, we will discuss the questions that appear below.\n",
        "\n",
        "### Discussion Questions\n",
        "\n",
        "1. What kind of data is suitable for a histogram?\n",
        "2. What is represented by the y-axis on the histogram?\n",
        "3. How many scores in a distribution are above the median? Is this always true?\n",
        "\n",
        "## III. Activity\n",
        "\n",
        "This activity will use data on home prices in Connecticut.\n",
        "\n",
        "Set up this activity by running the code block below. This will import the data. Reminder: to run the cell, you can either use `Shift` + `Enter`, or you can hit the play button."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y_Xoti3Kzyam"
      },
      "outputs": [],
      "source": [
        "#Setup Example Data\n",
        "import pandas as pd # import library\n",
        "data = pd.read_csv(\"https://raw.githubusercontent.com/vectrlab/apex-python-datasets/main/connecticut-housing/example.csv\") # read the datafile\n",
        "data # display the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghOen6Yxzyao"
      },
      "source": [
        "### 1. The Shape of a Population Distribution\n",
        "\n",
        "\n",
        "When you imported the data in the block above, you should have seen a preview of it in this notebook. This dataset reports average home sale prices for counties in Connecticut.\n",
        "\n",
        "- `data[\"Y\"]`: Name of the county in Connecticut    \n",
        "- `data[\"X\"]`: The median home sale price, in dollars\n",
        "- `data[\"X1\"]`: The mean home sale price, in dollars\n",
        "\n",
        "This dataset shows us the concept of **unit of analysis**. When we collect data from individuals, people are often the unit of analysis. However, that is not always the case. To identify the unit of analysis, consider who or what is being represented by one single score. In this example, each score is from a county in Connecticut, so the county is the unit of analysis. Note that it is not people and it is not homes. Our data file does not include the sale price of individual homes. Rather, it includes the average sale prices of homes in the county.\n",
        "\n",
        "Because we want to learn about home sales in counties in Connecticut, and all counties are represented in our data, the collection of all the scores in variable `X` forms a **population distribution**, or collection of scores from all members of our population of interest.\n",
        "\n",
        "To start, preview `data[\"X\"]` by copying and pasting it in the box below.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a5K6UCAOzyap"
      },
      "outputs": [],
      "source": [
        "# Enter data[\"X\"] on its own line to preview the distribution of median home sale prices.\n",
        "# data[\"X\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46vGyGKjzyaq"
      },
      "source": [
        "Next, summarize the distribution visually using a histogram. When you run the code, you will need to pick a color and bin size."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m5klXkchzyar"
      },
      "outputs": [],
      "source": [
        "#@title Histogram with custom binning and custom color: Median home prices\n",
        "# color names that work should include https://matplotlib.org/stable/gallery/color/named_colors.html\n",
        "import seaborn as sns # import library\n",
        "custom_color = input(\"Type the name of a color : \") # get user input for color\n",
        "custom_binwidth = int(input(\"Enter the width of the bins : \")) # get user input for bins\n",
        "sns.histplot(data[\"X\"], color = custom_color, binwidth = custom_binwidth) # display the histogram"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6lYNs3tAzyar"
      },
      "source": [
        "Consider the following questions:\n",
        "\n",
        "- How did you choose a bin size? Did previewing the data help in deciding the bin size?\n",
        "- What happens if you use a bin size of 10000? Why does this happen?\n",
        "- What happens if you use a bin size of 1? Caution: You may need to reload the page afterward. Why does this happen?\n",
        "- How would you describe the shape of this histogram to someone who has not seen it?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_cjXLOZKzyas"
      },
      "source": [
        "The histogram gives us an idea of the **shape of the distribution**. The shape is formed by connecting the top of each bar. As with most real-world data, the shape of this histogram is jagged and uneven. Despite that, there is a general shape that appears. \n",
        "\n",
        "The shape of a distribution is useful for two purposes:\n",
        "\n",
        "1. We can describe the shape of our collected data to quickly summarize the distribution. For example, if we describe the shape of a distribution as *bimodal* (having two modes), then it is easy for others to understand there were two clusters of scores that were the most frequent. Talking about the shape of the distribution is useful even if the distribution does not perfectly match.\n",
        "\n",
        "2. As we will see later, some types of distributions are expected to take a certain shape. Therefore, being able to identify distributions by their shape will be a useful skill for future modules.\n",
        "\n",
        "Next, we will introduce different types of distributions you may encounter. For each one, discuss how well our example matches the expected shape."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Itlkjtp5zyat"
      },
      "source": [
        "### Normal distributions\n",
        "\n",
        "The normal distribution is evident in a bell-shaped curve that tends to look like this:\n",
        "\n",
        "<img src=\"https://upload.wikimedia.org/wikipedia/commons/8/8c/Standard_deviation_diagram.svg\" alt=\"The normal distribution divided up by area showing .1%, 2.1%, 13.6%, 34.1%, 34.1%, 13.6%, 2.1% and .1% areas from left to right\">\n",
        "\n",
        "THe normal distribution has the following properties:\n",
        "\n",
        "- It applies to continuous, quantitative data\n",
        "- It is symmetrical about the mean\n",
        "- It does not have apparent skewness (which would make it not symmetrical)\n",
        "- The mean, median, and mode are roughly equal\n",
        "- The ends of the curve approach the x-axis but never touch it (called an asymptote)\n",
        "- Near one standard deviation away from the mean, the curve of the graph changes so that the graph starts curving upward\n",
        "\n",
        "Normal distributions emerge in data when there is one value (the mean) that is most common and values away from it tend to be progressively less common.\n",
        "\n",
        "### Skewed distributions\n",
        "\n",
        "Skewed distributions have a tail evident on one side of the distribution. When the tail is on the left side, or lowest values, of the distribution, we call it **negative skew**. When the tail is on the right side, the highest values, we call it **positive skew**.\n",
        "\n",
        "<img src=\"https://upload.wikimedia.org/wikipedia/commons/f/f8/Negative_and_positive_skew_diagrams_%28English%29.svg\" alt=\"Two distributions are shown, one labeled negative skew with a tail on the negative side, and the other labeled positive skew with a tail on the positive side\">\n",
        "\n",
        "Image credit: Rodolfo Hermans. This file is licensed under the [Creative Commons Attribution-Share Alike 3.0 Unported license](https://creativecommons.org/licenses/by-sa/3.0/deed.en).\n",
        "\n",
        "There are many ways that distributions are skewed. One way this pattern emerges is in the presence of an **outlier**, which is a low-frequency, extreme score. An outlier on the positive side, for example, can lead to positive skew."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQO6NBwozyau"
      },
      "source": [
        "Consider this question:\n",
        "\n",
        "- Based the histogram you genenrated earlier, does the distribution of median home prices seem to be skewed?\n",
        "- Generate the histogram of mean home prices in the block below. How does the distribution of *mean* home prices compare to the distribution of median home prices? "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-upKpDKczyav"
      },
      "outputs": [],
      "source": [
        "#@title Histogram with custom binning and custom color: Mean home prices\n",
        "# color names that work should include https://matplotlib.org/stable/gallery/color/named_colors.html\n",
        "import seaborn as sns # import library\n",
        "custom_color = input(\"Type the name of a color : \") # get user input for color\n",
        "custom_binwidth = int(input(\"Enter the width of the bins : \")) # get user input for bins\n",
        "sns.histplot(data[\"X1\"], color = custom_color, binwidth = custom_binwidth) # display the histogram"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3w_VY_r3zyav"
      },
      "source": [
        "### Bimodal and unimodal distributions\n",
        "\n",
        "Finally, some histograms have two or more areas of the highest frequency (the mode). When the tallest spot on the histogram occurs in two locations, the distribution is called **bimodal**. When there are more than two locations that are the highest, we call the distribution **multimodal**. Finally, some distributions have no mode (or every score is the mode, depending on how you look at it). In cases where every score has the same frequency, the distribution is said to be **uniform**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U6jM1Jdxzyaw"
      },
      "source": [
        "Consider these questions:\n",
        "\n",
        "- Generate the histogram for the median sale price and set the bin size to 50000. Is the distribution unimodal (with a single mode), bimodal, multimodal, or uniform? How do you know?\n",
        "- Does using a different bin size affect how many modes are evident in this distribution?\n",
        "- In any distribution, is it possible for bin size to affect how many modes appear?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "atMhl-erzyaw"
      },
      "source": [
        "### Z-Scores\n",
        "\n",
        "#### What do z-scores reveal?\n",
        "\n",
        "Z-scores tell us about the position of a score within a distribution. Z-scores are given in standard deviation units. That is, they are a property of each score that gives the distance between the score and the mean in standard deviation units.\n",
        "\n",
        "For example, a z-score of z = 3 is three standard deviations above the mean. A z-score of z = 0 is zero standard deviations above the mean, which is at the mean.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bIuyPuEzyaw"
      },
      "source": [
        "#### Raw score to z-score for known mean and SD\n",
        "\n",
        "Remember that the z-score is a distance from the mean, so every score in a distribution has a corresponding z-score. And, if two scores are the same, they will have the same z-score.\n",
        "\n",
        "To find a single z-score, we can use the formula `z = (score - mean)/sd`. Another way of saying this is that we are converting a raw score into a z-score. \n",
        "\n",
        "First, we need to find the mean and standard deviation from our population:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W3dd6OZfzyax"
      },
      "outputs": [],
      "source": [
        "#@title Population standard deviation\n",
        "import numpy as np # import library\n",
        "np.std(data[\"X\"], ddof=0) # display the population standard deviation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O5pjfeDyzyax"
      },
      "outputs": [],
      "source": [
        "#@title Population mean\n",
        "import numpy as np # import library\n",
        "np.mean(data[\"X\"]) # display the mean"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGmwRjlqzyax"
      },
      "source": [
        "With those two values, we can now use the z-score formula. For now, you'll have to copy and paste the values when prompted. Later, we will see that Python can do this more automatically.\n",
        "\n",
        "Use the code below to find the z-score that corresponds to the raw score of $300,000. Do not enter dollar signs or commas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F4dOKIAjzyay"
      },
      "outputs": [],
      "source": [
        "#@title Apply the z-score formula to user inputs\n",
        "# z = (score - mean)/pop_sd\n",
        "\n",
        "raw = float(input(\"Score = \")) # ask user to insert a new score\n",
        "mean = float(input(\"Mean = \")) # ask user to insert a new score\n",
        "sd = float(input(\"Input the standard deviation: \")) # ask user to insert a new score\n",
        "z = round((raw - mean)/sd, 2) # find z-score with formula, round to 2 decimal places\n",
        "\n",
        "print(f\"z = {z}\") # print result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z68k8LqXzyay"
      },
      "source": [
        "#### z-score to raw score for known mean and SD\n",
        "\n",
        "We can also convert z-scores into raw scores if we know the population mean and standard deviation. Try converting the z-score you just calculated back into a raw score."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "46vaDtI8zyay"
      },
      "outputs": [],
      "source": [
        "#@title Apply the raw score formula to user inputs\n",
        "# raw = score * sd + mean\n",
        "\n",
        "z = float(input(\"z = \")) # ask user to insert a new score\n",
        "mean = float(input(\"Mean = \")) # ask user to insert a new score\n",
        "sd = float(input(\"Input the standard deviation: \")) # ask user to insert a new score\n",
        "raw = round(z * sd + mean, 2) # find z-score with formula, round to 2 decimal places\n",
        "\n",
        "print(f\"score = {raw}\") # print result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crATEdNTzyaz"
      },
      "source": [
        "Consider these questions:\n",
        "\n",
        "- How many standard deivations away from the mean is the value 300,000?\n",
        "- What is the z-score for 100,000?\n",
        "- What does it mean for a z-score to be negative?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1x-Xb0Fzyaz"
      },
      "source": [
        "#### Converting a distribution to z-scores\n",
        "\n",
        "Often, we want to turn an entire distribution of raw scores into z-scores. The name for this process is called **standardizing**. Standardizing a distribution will alter its mean and standard deviation (it will have a mean of 0 and a standard deviation of 1), but it does not change its shape.\n",
        "\n",
        "To demonstrate, we will create a new variable, `data[\"Z]` to hold the z-scores corresponding to all of the median home prices."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fitXiETgzyaz"
      },
      "outputs": [],
      "source": [
        "#@title Generate Z-scores\n",
        "from scipy import stats\n",
        "data[\"Z\"] = stats.zscore(data[\"X\"])\n",
        "data[\"Z\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cH25qMq2zya0"
      },
      "source": [
        "Examine the histogram of z-scores. Notice how the mean and standard deviation has changed but the shape has not."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BZRnqlFRzya0"
      },
      "outputs": [],
      "source": [
        "#@title Histogram with custom binning and custom color: Z-Scores\n",
        "# color names that work should include https://matplotlib.org/stable/gallery/color/named_colors.html\n",
        "import seaborn as sns # import library\n",
        "custom_color = input(\"Type the name of a color : \") # get user input for color\n",
        "custom_binwidth = int(input(\"Enter the width of the bins : \")) # get user input for bins\n",
        "sns.histplot(data[\"Z\"], color = custom_color, binwidth = custom_binwidth) # display the histogram"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkRxSViBzya0"
      },
      "source": [
        "#### Converting a distribution of z-scores into raw scores\n",
        "\n",
        "So that you have a complete set of z-score tools, note that we can convert a standardized distribution into raw scores, as well."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N8cpf4Htzya1"
      },
      "outputs": [],
      "source": [
        "#@title Generate Raw Scores\n",
        "from scipy import stats\n",
        "raw_scores = [] # below is a list of raw scores\n",
        "sd = np.std(data[\"X\"], ddof=0) # display the population standard deviation\n",
        "mean = data[\"X\"].mean()\n",
        "for z in data[\"Z\"]: # convert from z-scores\n",
        "  raw_scores.append(z * sd + mean)  # Save each raw score into list\n",
        "  \n",
        "raw_scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AYAQS8iMzya1"
      },
      "source": [
        "#### Using z-scores to detect outliers\n",
        "\n",
        "We noticed earlier that the distribution of median home prices is positively skewed. The appearance of a tail on the right side of the distribution says that the home prices in some counties are much higher than most others. We call extreme, low-frequency scores **outliers**, and they can occur on either the positive side or negative side of the distribution. \n",
        "\n",
        "Because z-scores tell us the number of standard deviations away from the mean, they are useful for detecting outliers in a distribution.\n",
        "\n",
        "We can use our z-score distribution to see if any scores are above 3. z = 3 is a common cutoff used to identify outliers. While we are at it, we should look for z-scores on the other side of the distribution, those below z = - 3."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j3KqM61Azya1"
      },
      "outputs": [],
      "source": [
        "#@title Selecting cases in a dataframe\n",
        "data[data[\"Z\"] > 3] # Look for z-scores above 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NFTLsdXFzya1"
      },
      "outputs": [],
      "source": [
        "#@title Selecting cases in a dataframe\n",
        "data[data[\"Z\"] < -3] # Look for z-scores below -3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CVJwER7Ozya2"
      },
      "source": [
        "#### Keeping or excluding an outlier from your data\n",
        "\n",
        "You may get advice to remove or exclude an outlier score from your data. Be careful with this. Just because a score is an outlier does not mean it does not belong in the data. In our example, some counties have higher median home prices. If we exclude the highest ones, we will have a distribution that is more normal at a cost of discarding information. In this case, we will **bias** our estimates of home prices if we exclude the highest scores. Sometimes outliers are legitimate scores that belong in our data, even if they create messy distribution shapes. When outliers are the result of an error (like a typo), then such errors should be removed. In all, we want to avoid biasing our distributions while also looking for and fixing errors."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aINGQlJvzya2"
      },
      "source": [
        "#### Area under the curve problems\n",
        "\n",
        "When a distribution is normal or approximately normal, and we know its mean and standard deviation, new calculations are possible.\n",
        "\n",
        "In a prior module, we introduced the **empirical rule**. It says that a certain proportion of scores fall within each standard deviation:\n",
        "\n",
        "<img src=\"https://upload.wikimedia.org/wikipedia/commons/8/8c/Standard_deviation_diagram.svg\" alt=\"The normal distribution divided up by area showing .1%, 2.1%, 13.6%, 34.1%, 34.1%, 13.6%, 2.1% and .1% areas from left to right\">\n",
        "\n",
        "Notice that 34.1% of the scores in the normal distribution are between the mean and one standard deviation. This will always be the case (or approximate it) when the distribution is normal (or approximately normal). Therefore, we can solve two kinds of problems using this information:\n",
        "\n",
        "1. We can find the area under the curve given any two boundary scores.\n",
        "2. We can find a boundry score that corresponds to an area.\n",
        "\n",
        "For now, it will be useful to learn to solve these two kinds of problems. Later, we will use this technique on other kinds of distributions.\n",
        "\n",
        "These problems require a known population mean and standard deviation and for the population to be approximately normal.\n",
        "\n",
        "#### Find the area under the curve\n",
        "\n",
        "In the first type of problem, you input the mean and standard deviation and then enter two bounds. Here is an example question:\n",
        "\n",
        "- What proportion of median home prices were between $100,000 and $200,000?\n",
        "\n",
        "Use the calculator below using the mean and population you found earlier.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eoHsfmmszya2"
      },
      "outputs": [],
      "source": [
        "#@title Find Area Under the Curve\n",
        "from scipy.stats import norm\n",
        "\n",
        "mean = float(input(\"Specify your mean: \")) # insert the mean\n",
        "stdev = float(input(\"Specify your standard deviation: \")) # insert the standard deviation\n",
        "lower_bound = float(input(\"Specify your lower bound: \")) # insert the lower bound\n",
        "upper_bound = float(input(\"Specify your upper bound: \")) # insert the upper bound\n",
        "\n",
        "area_under_curve = norm.cdf(upper_bound, loc=mean, scale=stdev) - norm.cdf(lower_bound, loc=mean, scale=stdev) # calculate the area under the curve by subtracting the larger area (using upper bound) from smaller one (using lower bound)\n",
        "print(f\"Area under the curve from {lower_bound} to {upper_bound} is {round(area_under_curve, 2)}\") # print out result; round answer to two signigicant figures\n",
        "\n",
        "# see: \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DoRG9wvzya3"
      },
      "source": [
        "#### Find the boundary score\n",
        "\n",
        "If median home price was in the 80th percentile (i.e., higher than 80% of the other prices), what is the price? In other words, what score is associated with the 80th **percentile**? In the calculator below, enter the percentile as a proportion: 0.8 instead of 80%."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M_C5PhC3zya3"
      },
      "outputs": [],
      "source": [
        "#@title Inverse Cumulative Distribution Function\n",
        "from scipy.stats import norm\n",
        "\n",
        "mean = float(input(\"Specify your mean: \")) # insert the mean\n",
        "stdev = float(input(\"Specify your standard deviation: \")) # insert the standard deviation\n",
        "percentile = float(input(\"Specify the percentile (from 0-1 range): \")) # insert percentile\n",
        "inv_norm_ans = norm.ppf(percentile, loc=mean, scale=stdev) # find inverse norm result with norm.ppf method\n",
        "print(f\"With mean {mean} and standard deviation {stdev}, the {int(percentile*100)}th percentile is {round(inv_norm_ans, 2)}\") # print out result; round answer to two significant figures\n",
        "\n",
        "# norm.ppf returns a *percentile* confidence interval for a one-tailed test\n",
        "# for example, when we specify 0.95, we indicated the area under the curve to be 0.95\n",
        "# with loc to be our mean and scale to be our standard deviation\n",
        "# In R, it is qnorm(0.95, 0, 1) or qnorm(0.05,0,1,lower.tail=FALSE) with mean 0 and standard deviation 1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lBD4Jp5Mzya3"
      },
      "source": [
        "----\n",
        "### What's Next\n",
        "\n",
        "In this module, we worked with population distributions, especially ones that were close to normal. Our research data is more often done on sample data instead of population data, so we need a few more tools to work with samples. This includes the introduction of a third kind of distribution, the **sampling distribution**. \n",
        "\n",
        "#### Discussion questions\n",
        "\n",
        "1. If you asked people how many years they have spent in a job and found the distribution to be bimodal, what would that mean?\n",
        "2. Why does the z-score distribution have the same shape as the raw score distribution?\n",
        "3. What does z = 2 mean? What does z = 0 mean? What does z = -4 mean?\n",
        "4. Why is z = 3 used as a cutoff to detect outliers?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eN_zLY_yzya3"
      },
      "source": [
        "----\n",
        "## IV. Summary\n",
        "\n",
        "- In this module, we took a closer look at the **shape** of a distribution visualized using **histograms**.\n",
        "- We learned that we can describe the shape of the distribution as a way of summarizing it. \n",
        "- Z-scores tell us the distance from the mean in standard deviation units, and every score has a corresponding z-score.\n",
        "- We can convert single scores into z-scores or **standardize** an entire distribution into z-scores.\n",
        "- When we assume a distribution is normal, we can make inferences about the **area under the curve**.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}